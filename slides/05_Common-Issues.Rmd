---
title: "Common Issues in Data Cleaning"
output:
  xaringan::moon_reader:
    css: ["style.css", "default"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r child = "setup.Rmd"}
```

```{r xaringan-panelset, echo=FALSE, eval=TRUE}
xaringanExtra::use_panelset()
```

```{r xaringan-tachyons, echo=FALSE, eval=TRUE}
xaringanExtra::use_tachyons()
```

```{r imgs setup, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
```

```{r, include=FALSE, eval=TRUE}
library(tibble)
library(dplyr)
library(unheadr)
library(stringr)
library(janitor)
library(snakecase)
library(readr)
library(tidyr)
library(naniar)
library(gt)
```

class: center, middle, dk-section-title
background-image:url("images/michael-We2t3suGiYk-unsplash.jpg")
background-size: cover
# Common Issues in Real-World Data and Their Consequences

---

## Real-world data

--

- May not be readily imported  


--


- May not function properly within analysis software  


--

- Often contains issues that go unnoticed until they: 

- break a workflow
- introduce biases
- waste resources (computational, $)  

---

## General data cleaning workflows 

.large[
0\. Rectangular data
]
.large[
1\. Variable names
]
.large[
2\. Observational units
]
.large[
3\. Grouping variables
]

---

## Less interpretation

.large[
Whitespace, duplication, letter case
]

## More interpretation

.large[
Cleaning numeric variables, unbreaking values, extracting target data
]

---
class: center, middle, dk-section-title
background-image:url("images/james-rathmell-t0iwmK0WC0Y-unsplash.jpg")
background-size: cover
# Unusable Headers 

---

## Unusable headers 


Inconsistent or uninformative names  

```{r, echo=FALSE, eval=TRUE}
useless <- tibble::tribble(
  ~X,    ~X1, ~X2, ~mean_Score, ~AVERAGE.SCORE,
  "UMN", "EAST", "A",         7.7,          7.701,
  "UV", "WEST", "B",         8.9,           8.89,
  "UNLV", "EAST", "C",         9.2,          9.199
)
useless %>% 
  gt() %>% 
  tab_options(table.background.color="#f4f4f9")
```


- Distinct != informative 

--

- More difficult to remember and specify  

--

- Do not sort well  


---

## Unusable headers


Names broken across rows


```{r, echo=FALSE, eval=TRUE}
tibble::tribble(
  ~X,    ~X1, ~X2,   ~mean,     ~AVERAGE,
  NA,     NA,  NA, "Score",      "SCORE",
  "UMN", "EAST", "A",   "7.7",      "7.701",
  "UV", "WEST", "B",   "8.9",       "8.89",
  "UNLV", "EAST", "C",   "9.2",      "9.199"
) %>% 
  gt(useless) %>% 
  tab_options(table.background.color="#f4f4f9")
```


- Variable names appear in >1 rows  

--

- Header fragments mixed with data

--

- Separators become implicit  

--

- `NAs` introduced

---

## Cleaning column names

### Syntactically valid variable names


- Contain only letters, numbers, dots or underscores

--

- Start with a letter or a dot (not followed by a number)

--

- Not reserved words (_if_, _else_, _for_, _in_, _TRUE_, _NaN_, etc.)  


---

## Cleaning column names 

.left-column[
</br>
.large[
Rename or clean with .orange.b[regex]
]
]
.right-column[
.large[
Clean names with ðŸ“¦ **.rrured.b[`janitor`]**  
]
- Strips special characters

- Changes spaces and dots to underscores

- User-defined capitalization (default is snake_case)

]

---
```{r, echo=FALSE, eval=TRUE}
badnames <- tibble::tribble(
  ~X,    ~X1, ~X2, ~mean_Score, ~AVERAGE.SCORE,
  "UMN", "EAST", "A",         7.7,          7.701,
  "UV", "WEST", "B",         8.9,           8.89,
  "UNLV", "EAST", "C",         9.2,          9.199
)
```

```{r, eval=TRUE}
badnames
```

```{r, eval=TRUE}
badnames %>% 
  clean_names()
```

---

## Broken headers

```{r, echo=FALSE, eval=TRUE}
badheaders <- tibble::tribble(
  ~X,    ~X1, ~X2,   ~mean,     ~AVERAGE,
  NA,     NA,  NA, "Score",      "SCORE",
  "UMN", "EAST", "A",   "7.7",      "7.701",
  "UV", "WEST", "B",   "8.9",       "8.89",
  "UNLV", "EAST", "C",   "9.2",      "9.199"
)

```

```{r, eval=TRUE}
badheaders
```

---

## Broken headers

.large[
Mash the top _n_ data rows column-wise with ðŸ“¦ .rrured.b[`unheadr`]
]

```{r, eval=FALSE}
badheaders %>% 
  *  mash_colnames(n_name_rows = 1, # number of data rows with header fragments
                   sep = "_") # separator for collapsing header fragments
```

---

```{r, eval=TRUE}
badheaders %>% 
  mash_colnames(n_name_rows = 1,
                sep = "_")
```


```{r, eval=TRUE}
badheaders %>% 
  mash_colnames(n_name_rows = 1,
                sep = "_") %>% 
  clean_names()
```

---

class: my-turn
## My turn

- Import a .csv file with problematic headers (MPAS-mine.csv)

--

- Make the variable names usable by placing all header fragments in a single header row  

--

- Clean the names for consistency, using snake case


---

class: inverse

## Your turn


- Import a .csv file with problematic headers (MPAS-your.csv)

--

- Make the variable names usable by placing all header fragments in a single header row  

--

- Clean the names for consistency


---
class: center, middle, dk-section-title
background-image:url("images/farnoosh-abdollahi-vIkABUsLEDY-unsplash.jpg")
background-size: cover
# Whitespace

---

## Whitespace

.large[
Does not correspond to a visible character, but occupies space in a string.
]

--

```{r, eval=TRUE}
string_a <- "This string starts with a T"
string_b <- " This string starts with a space"
string_c <- "This string has trailing whitespace "
tibble(strings=c(string_a,string_b,string_c))
```

---

class: middle

```{r, eval=TRUE}
string_a <- "R for the rest of us"
string_b <- " R for the rest of us"
string_c <- "R for the rest of us "
string_d <- " R for the rest of us "
string_e <- "R for the   rest of us"
RrU <- tibble(strings=c(string_a,string_b,string_c,string_d,string_e))
RrU
```

---

```{r, eval=TRUE}
RrU %>% 
  distinct(strings)
```

---

### Issues

- Leading whitespace

--

- Trailing whitespace

--

- Duplicated whitespace within strings


---

## Diagnosing whitespace issues
>**"R for the rest of us"**   
(six words, five spaces)  

--

Count words, then spaces

```{r, eval=TRUE}
str_count(RrU$strings, '\\w+')
```

```{r, eval=TRUE}
str_count(RrU$strings, '\\s')
```

---

### Ambiguous strings

**`is.ambiguous_string()`**  

.large[
- Unexported function from ðŸ“¦ .rrured.b[`pillar`]
- Used by ðŸ“¦ .rrured.b[`tibble`] to reveal ambiguous strings when printing to console
- Ambiguous strings defined with a .orange.b[regexp]]

```{r, eval=FALSE}
function (x) 
{
  !is.na(x) & grepl("^$|^ | $|\\\\|\"", x)
}
```

---

```{r, eval=TRUE}
RrU %>% mutate(is_ambiguous = pillar:::is_ambiguous_string(strings))
```

```{r, eval=TRUE}
RrU %>% mutate(is_ambiguous = str_detect(strings,"^$|^ | $"))
```

---

### Check **all** columns of type _character_


```{r, eval=TRUE}
RrU %>% mutate(across(where(is.character),pillar:::is_ambiguous_string))
```

---

### Check **all** columns of type _character_

```{r, eval=TRUE}
RrU %>% mutate(across(where(is.character),
                      str_detect,"^$|^ | $"))
```

---

## Removing whitespace: `trim_ws()`

.large[
Argument to `read_x` functions in ðŸ“¦ .rrured.b[`readr`]

Trims leading and trailing whitespace from each field during import. 
]
`TRUE` by default for **`read_csv()`** and **`read_tsv()`**  
`FALSE` by default for **`read_delim()`**

---

## Removing whitespace: `str_squish()`

String manipulation function from ðŸ“¦ **.rrured.b[`stringr`]**   

Removes whitespace from the start and end of a string and reduces repeated whitespace inside the string

```{r, eval=TRUE}
RrU %>% 
  mutate(strings_sq = str_squish(strings))
```

---

## Count words and spaces (again)  

.large[
**"R for the rest of us"** (six words, five spaces)
]

```{r, eval=TRUE}
str_count(RrU$strings_sq, '\\w+')
str_count(RrU$strings_sq, '\\s')
```

---

## Check ambiguous strings (again)

```{r, echo=FALSE}
RrU
```

```{r, eval=TRUE}
RrU %>% mutate(across(where(is.character),
                      str_detect,"^$|^ | $"))
```

---

```{r, eval=TRUE}
RrU %>% 
  mutate(strings = str_squish(strings)) %>% 
  distinct()
```

---

class: my-turn

## My turn

- In the Marine Protected Areas dataset from the previous lesson (MPAS-mine.csv), check the _geographic_location_ variable for leading or trailing whitespace and remove it if necessary.

---

class: inverse

## Your turn

- In the Marine Protected Areas dataset from the previous lesson (MPAS-your.csv), check the _Country_ variable for leading or trailing whitespace and remove it if necessary.

---

class: center, middle, dk-section-title
background-image:url("images/snake-mylene2401.jpg")
background-size: fill
# Letter Case 

---

## Letter case

### Strings in R are case sensitive

Changing letter case:

--

- Removes unwanted variation

--

- Improves noise/signal ratio

--

- Adds consistency 

--

- Improves readability (more shape contrast in lower vs. upper case, for many popular fonts)

---
```{r, echo=FALSE, eval=TRUE}
districts <- 
  tibble::tribble(
    ~District, ~`Contribution.(USD)`, ~Constituents,
    "Orange walk",                10990L,           12L,
    "TOLEDO",                30000L,            7L,
    "Stann Creek",                 3400L,            9L,
    "Toledo",                21999L,            7L,
    "Orange WalK",                 8800L,           12L,
    "Orange Walk",                  800L,           12L,
    "Orange Walk",                55000L,           12L,
    "stann creek",                22999L,            9L,
    "Toledo",                 4900L,            7L
  )
```


.panelset[
.panel[.panel-name[Districts]
```{r, echo=FALSE, eval=TRUE}
districts %>% gt() %>% 
  tab_options(table.background.color="#f4f4f9")
```
]

.panel[.panel-name[Data setup]
```{r panel-chunk, fig.show='hide'}
districts <- tibble::tribble(
    ~District, ~`Contribution.(USD)`, ~Constituents,
    "Orange walk",                10990L,           12L,
    "TOLEDO",                30000L,            7L,
    "Stann Creek",                 3400L,            9L,
    "Toledo",                21999L,            7L,
    "Orange WalK",                 8800L,           12L,
    "Orange Walk",                  800L,           12L,
    "Orange Walk",                55000L,           12L,
    "stann creek",                22999L,            9L,
    "Toledo",                 4900L,            7L
  )
```
]
]

---

## Total contributions by district
```{r, eval=TRUE}
districts %>% group_by(District) %>% 
  summarize(total_contribution = sum(`Contribution.(USD)`))
```

---

## Detecting lower and upper case

```{r, eval=TRUE}
districts %>% 
  mutate(lowercase = str_detect(District,"^[a-z\\s]+$"),
                     uppercase = str_detect(District,"^[A-Z\\s]+$")) %>% 
  select(District, lowercase, uppercase)
```

---

## Changing case with ðŸ“¦ .rrured.b[`snakecase`]    

```{r, eval=FALSE}
to_any_case(strings, case)
```

.pull-left[
**camelCase** - capitalize all words following the first word, no spaces  

**snake_case** - all lowercase, underscores between words  

**slug-case** - all lowercase, dashes between words  
]

.pull-right[
**Title case** - All words capitalized except articles (_a_, _the_, _and_, etc.)  

**Sentence case** - First word capitalized, spaces between words  
]

---

## Convert case first with `to_any_case()`


```{r, eval=TRUE}
districts %>%
  mutate(District_clean = to_any_case(District, "title",
                                      parsing_option = 0 #<<
  )) %>%  
  group_by(District_clean) %>%
  summarize(total_contribution = sum(`Contribution.(USD)`))
```

> `?to_any_case()` for details on parsing options
---

## ðŸ“¦ .rrured.b[`snakecase`] shortcuts


```{r, eval=TRUE}
districts %>% 
  mutate(District_clean = to_title_case(District, #<<
                                        parsing_option = 0 #<<
  )) %>% 
  group_by(District_clean) %>%
  summarize(total_contribution = sum(`Contribution.(USD)`))
```

---

class: my-turn
## My turn

- Import the Marine Protected Areas dataset (MPAS-mine.csv) and summarize the number of Marine Protected Areas by United Nations Geoscheme Region (_UN Geoscheme_).

---
class: inverse
## Your turn

- Import the Marine Protected Areas dataset (MPAS-your.csv), and summarize the number of Marine Protected Areas by country (_Country full_).

---

class: center, middle, dk-section-title
background-image:url("images/hans-heiner-buhr-OKe4Q8azVNU-unsplash.jpg")
background-size: cover
# Missing, Implicit, or Misplaced Grouping Variables

---

### Missing ... ðŸ¤·

---

### Implicit or misplaced

--

.large[
- Embedded as subheaders  
]

.large[
- Part of a compound value (next lesson)
]

---

## Embedded subheaders

.left-column[
**Hot drinks**
Coffee  
Tea  
Hot chocolate
**Cold Drinks**
Soda  
Juice  
Water  
Beer  
]
.right-column[

- Rows that correspond to values in grouping variables   

- Embedded in the data rectangle instead of in their own column   

- Human-readable, but hard to work with (for example: calculating group-wise summaries)

]

---

```{r, echo=FALSE, eval=TRUE}
cafeteria <- 
  tibble::tribble(
    ~Item, ~Price,
    "Hot Drinks",     NA,
    "Coffee",    12L,
    "Tea",     9L,
    "Hot chocolate",     9L,
    "Cold Drinks",     NA,
    "Soda",    10L,
    "Juice",    13L,
    "Water",     8L,
    "Beer",     8L
  )
cafeteria_tidy <- 
  tibble::tribble(
    ~Item, ~Price,   ~drink_type,
    "Coffee",    12L,  "Hot Drinks",
    "Tea",     9L,  "Hot Drinks",
    "Hot chocolate",     9L,  "Hot Drinks",
    "Soda",    10L, "Cold Drinks",
    "Juice",    13L, "Cold Drinks",
    "Water",     8L, "Cold Drinks",
    "Beer",     8L, "Cold Drinks"
  )

```

.panelset[
.panel[.panel-name[Cafeteria Menu]
```{r, echo=FALSE, eval=TRUE}
cafeteria %>% gt() %>% 
  tab_options(table.background.color="#f4f4f9")
```
]

.panel[.panel-name[Data setup]
```{r panel-chunk2, fig.show='hide'}
cafeteria <- 
  tibble::tribble(
    ~Item, ~Price,
    "Hot Drinks",     NA,
    "Coffee",    12L,
    "Tea",     9L,
    "Hot chocolate",     9L,
    "Cold Drinks",     NA,
    "Soda",    10L,
    "Juice",    13L,
    "Water",     8L,
    "Beer",     8L
  )

```
]

.panel[.panel-name[Cafeteria Menu (tidy)]
```{r, echo=FALSE, eval=TRUE}
cafeteria_tidy %>% gt() %>% 
  tab_options(table.background.color="#f4f4f9")
```
]

.panel[.panel-name[Data setup (tidy)]
```{r panel-chunk3, fig.show='hide'}
cafeteria_tidy <- 
  tibble::tribble(
    ~Item, ~Price,   ~drink_type,
    "Coffee",    12L,  "Hot Drinks",
    "Tea",     9L,  "Hot Drinks",
    "Hot chocolate",     9L,  "Hot Drinks",
    "Soda",    10L, "Cold Drinks",
    "Juice",    13L, "Cold Drinks",
    "Water",     8L, "Cold Drinks",
    "Beer",     8L, "Cold Drinks"
  )

```
]
]

---

## Tidying embedded subheaders
ðŸ“¦ .rrured.b[`unheadr`]

**`untangle2()`** function 


1. Match with a .orange.b[regular expression]

2. Position (sometimes) identifiable as the rows with NAs in all the variables except for the one with the subheaders


---

## `untangle2()`

```{r, echo=FALSE, eval=TRUE}
cafeteria
```

--

```{r, eval= FALSE}
untangle2(df,
          regex, # regular expression to match subheaders
          orig,  # variable with the subheaders
          new)   # name of the new variable with the group values
```

---

## `untangle2()`

Match using .orange.b[regex]
```{r, eval= FALSE}
cafeteria %>% 
  untangle2("Drinks$", Item, drink_type) %>% #<<
  clean_names()
```

---

## `untangle2()`

.orange.b[Regexp] match and summarize
```{r, eval=TRUE}
cafeteria %>% 
  untangle2("Drinks$", Item, drink_type) %>% 
  clean_names()
```


```{r, eval=TRUE}
cafeteria %>% 
  untangle2("Drinks$", Item, drink_type) %>% 
  clean_names() %>% 
  group_by(drink_type) %>% 
  summarize(mean_price=mean(price))
```

---

### Alternation

```{r, eval=TRUE}
cafeteria %>% 
  untangle2("Hot Drinks|Cold Drinks", Item, drink_type) %>% 
  clean_names()
```

---

### Alternation

```{r, eval=TRUE}
cafeteria %>% 
  untangle2("Hot Drinks|Cold Drinks", Item, drink_type) %>% 
  clean_names() %>% 
  group_by(drink_type) %>% 
  summarize(mean_price=mean(price))
```

---

### Identify subheaders by context (`NA` values)

```{r, eval=TRUE}
cafeteria %>%
  filter(across(-Item, is.na)) %>%
  select(Item) %>%
  mutate(tag = paste0("subheader_", Item)) %>% 
  right_join(cafeteria) %>%
  untangle2("^subheader", tag, drink_type) %>%
  select(-tag) %>%
  mutate(drink_type = stringr::str_remove(drink_type, "^subheader_"))
```

---


```{r, eval=TRUE}
cafeteria %>%
  filter(across(-Item, is.na)) %>%
  select(Item) %>%
  mutate(tag = paste0("subheader_", Item)) 
```


--

Filter rows with NAs in all columns except the one holding the subheaders  

--

Keep only the column with subheaders  

--

Create a new variable that includes a pattern that can be matched with .orange.b[regex]


---


```{r, eval=FALSE}
... %>%    
  right_join(cafeteria) %>%
  untangle2("^subheader", tag, drink_type) %>%
  select(-tag) %>%
  mutate(drink_type = stringr::str_remove(drink_type, "^subheader_"))
```

--

Join resulting object with original data

--

Put implicit grouping variable into its own column

--

Clean up resulting data


---

class: my-turn
## My turn
.large[
- Load the `primates2017` dataset bundled with ðŸ“¦ `unheadr` and create a new column that groups the different species by geographic region. 
]

---

class: inverse
## Your turn
.large[
- Load the `primates2017` dataset bundled with ðŸ“¦ `unheadr` and create a new column that groups the different species by taxonomic family.  
]

> In biology, taxonomic families all end in the suffix "_DAE_"  

.large[- How many different ways can you identify the embedded subheaders in these data?
]

---

class: center, middle, dk-section-title
background-image:url("images/max-vertsanov-qvRuue12Huw-unsplash.jpg")
background-size: fill
# Compound Values  

---

## Compound values

.large[* Not tidy]  

--

.large[* Potential loss of variables or observations]

---

### Tidying compound values 

.pull-left[Split on a separator, then:

**`separate()`** columns  

**`unnest()`** rows
]

.pull-right[
Match with .orange.b[regex], then:  

**`str_extract()`** substrings into new columns
]

---

```{r, include=FALSE, eval=TRUE}
households <- 
  tibble::tribble(
    ~Participant.ID,     ~Education,            ~Residence, ~Bonus,
    "GHC21",   "Vocational",    "Living Alone-Cat",   500L,
    "MYL11",  "High School",     "Family Home-Cat",   400L,
    "LLB16",     "Graduate",     "Family Home-Dog",   400L,
    "AAH08",   "Vocational", "Shared Housing-None",   450L,
    "PCG91",   "Vocational",   "Family Home-Other",   500L,
    "ACC22, PMM02",  "High School", "Shared Housing-None",   400L,
    "MJM13", "Postgraduate",    "Living Alone-Dog",   500L
  )
```


.panelset[
.panel[.panel-name[Households]
```{r echo=FALSE, eval=TRUE}
gt(households)
```
]

.panel[.panel-name[Data setup]
```{r householdsetup, fig.show='hide'}
households <- 
  tibble::tribble(
    ~Participant.ID,     ~Education,            ~Residence, ~Bonus,
    "GHC21",   "Vocational",    "Living Alone-Cat",   500L,
    "MYL11",  "High School",     "Family Home-Cat",   400L,
    "LLB16",     "Graduate",     "Family Home-Dog",   400L,
    "AAH08",   "Vocational", "Shared Housing-None",   450L,
    "PCG91",   "Vocational",   "Family Home-Other",   500L,
    "ACC22, PMM02",  "High School", "Shared Housing-None",   400L,
    "MJM13", "Postgraduate",    "Living Alone-Dog",   500L
  )
```
]
]

---

## Separate Residence and 'Pet' variables

```{r, eval=TRUE}
households %>% 
  separate(col = Residence, # columns to separate
           into = c("Residence", "Pet"), # names of new variables to create 
           sep = "-") # separator between columns
```

---

### Match and extract
.large[
.orange.b[Regexp] for ~'last word in string'
]
```{r, eval=TRUE}
households %>% 
  mutate(Pet = str_extract(Residence,"\\b\\w+$"))
```

---

## Unnest Participant IDs

**`str_split()`** from ðŸ“¦ **.rrured.b[`stringr`]**  
- Split the compound value at the separator "`, `"   

--

**`unnest()`** from ðŸ“¦ **.rrured.b[`tidyr`]** 
- Flatten each element from the split into a row

---

#### List of vectors  
```{r, eval=TRUE}
str_split(households$Participant.ID,", ")
```

---

#### Within the data rectangle:

```{r, eval=TRUE}
households %>%
  mutate(Participant.ID=str_split(households$Participant.ID,", "))
```

---

#### Flatten to rows
```{r, eval=TRUE}
households %>% 
  mutate(Participant.ID=str_split(Participant.ID,", ")) %>% 
  unnest(cols = Participant.ID) #<<
```

---

#### Separate and unnest
```{r, eval=TRUE}
households %>% 
  separate(col = Residence, into =  c("Residence", "Pet"),sep = "-") %>%  
  mutate(Participant.ID=str_split(Participant.ID,", ")) %>% 
  unnest(cols = Participant.ID) 

```

---

class: my-turn
## My turn

.large[
- Import the Marine Protected Areas dataset (MPAS-mine.csv), separate the country codes variable (ISO3 and UN scheme) and unnest the Reference variable.]

--

.large[
- Which Reference appears the most?
]

---

class: inverse
## Your turn

.large[
- Import the Marine Protected Areas dataset (MPAS-your.csv), separate the country codes variable (ISO3 and UN scheme) and unnest the Reference variable.]

--

> Keep an eye on the separators

--

.large[
- Optional: Arrange the data by ISO3 country code
]

---

class: center, middle, dk-section-title
background-image:url("images/armelle-danjour-kwGqIuNrM5E-unsplash.jpg")
background-size: cover
# Duplicates  

---

## Problems with duplicates

--

.large[- Bloat our data]  

--

.large[- Unintentional repetition can be costly]  

--

.large[- Inaccurate reporting (double counting, inflated or biased summary statistics)]

---

## What can we do?


Identify with `get_dupes()` from ðŸ“¦ .rrured.b[`janitor`]  

--

Discard with `distinct()` from ðŸ“¦ .rrured.b[`dplyr`]  


---

## Duplicated values  


- Across all variables  

--

- Across the variable(s) defining the observational units  

--

- Across arbitrary sets of variables


---

```{r, include=FALSE, eval=TRUE}
pizza_orders <- 
  tibble::tribble(
    ~CustomerID,                             ~Address,           ~City,     ~State, ~Country,
    "Newman", "Apartment 5E, 129 West 81st Street", "New York City", "New York",    "USA",
    "susan_A",               "185 West 74th Street", "New York City", "New York",    "USA",
    "susan_A",               "185 West 74th Street", "New York City", "New York",    "USA",
    "js1994", "Apartment 5A, 129 West 81st Street", "New York City", "New York",    "USA",
    "Eric",    "Unit 1B, 4186 Willoughby Avenue",      "Brooklyn", "New York",    "USA",
    "Dash",    "Unit 1B, 4186 Willoughby Avenue",      "Brooklyn", "New York",    "USA",
    "Rakeem",    "Unit 1B, 4186 Willoughby Avenue",      "Brooklyn", "New York",    "USA"
  )
```


.panelset[
.panel[.panel-name[pizza_orders]
```{r, echo=FALSE, eval=TRUE}
pizza_orders %>% kableExtra::kable()
```
]

.panel[.panel-name[Data setup]
```{r pizzasetup, fig.show='hide'}
pizza_orders <- 
  tibble::tribble(
    ~CustomerID,                             ~Address,           ~City,     ~State, ~Country,
    "Newman", "Apartment 5E, 129 West 81st Street", "New York City", "New York",    "USA",
    "susan_A",               "185 West 74th Street", "New York City", "New York",    "USA",
    "susan_A",               "185 West 74th Street", "New York City", "New York",    "USA",
    "js1994", "Apartment 5A, 129 West 81st Street", "New York City", "New York",    "USA",
    "Eric",    "Unit 1B, 4186 Willoughby Avenue",      "Brooklyn", "New York",    "USA",
    "Dash",    "Unit 1B, 4186 Willoughby Avenue",      "Brooklyn", "New York",    "USA",
    "Rakeem",    "Unit 1B, 4186 Willoughby Avenue",      "Brooklyn", "New York",    "USA"
  )

```
]
]

---

## Identify with **`get_dupes()`** from ðŸ“¦ .rrured.b[`janitor`]  


```{r, eval=TRUE}
pizza_orders %>% 
  get_dupes() # all variables by default
```

--

* Adds a `dupe_count` variable showing the number of rows sharing the duplicated values  
* Puts the input variables at the beginning of the resulting data frame 

---

### `get_dupes()` using variable with chosen observational unit


```{r, eval=TRUE}
pizza_orders %>% 
  get_dupes(CustomerID)
```

---

### `get_dupes()` using custom combination

> now accepts ðŸ“¦ `tidyselect` helpers

```{r, eval=TRUE}
pizza_orders %>% 
  get_dupes(Address, starts_with("Cit")) 
```

---

## Discard with `distinct()` from ðŸ“¦ .rrured.b[`dplyr`]


```{r, eval=TRUE}
pizza_orders %>% 
  distinct() # all variables by default
```

---

### `distinct()` using variable with chosen observational unit


```{r, eval=TRUE}
pizza_orders %>% 
  distinct(CustomerID, .keep_all = TRUE)
```

--

> Use `.keep_all = FALSE` (default) to drop all other variables

---

### `distinct()` using custom combination


>  ðŸ“¦ `tidyselect` helpers enabled by using `across` semantics

```{r, eval=TRUE}
pizza_orders %>% 
  distinct(across(c(Address, starts_with("Cit")))) 
```

---

### `distinct()` using custom combination

>âš ï¸ If `.keep_all = TRUE` and there are duplicates in other variables, `distinct` only keeps the fist row 

```{r, eval=TRUE}
pizza_orders %>% 
  distinct(across(c(Address,starts_with("City"))), .keep_all = TRUE) 
```

---

class: my-turn

## My turn

--

- Load the messy Age of Empires units dataset bundled with `unheadr` (AOEunits_raw) and discard units that are not of Type "Archer".

--

- Identify duplicated records across all variables.

--

- Remove duplicated records across all variables.


---

class: inverse
## Your turn

- Load the messy Age of Empires units dataset bundled with `unheadr` (AOEunits_raw) and keep only units of Type "Cavalry".

--

- Identify duplicated records across all variables.

--

- Remove duplicated records across all variables.


---

class: center, middle, dk-section-title
background-image:url("images/jonathan-safa-YcxOAC5DpDA-unsplash.jpg")
background-size: cover
# Broken Values

---

## Broken values


Values broken across rows, often to save horizontal space on a page or column, and carried over onto machine-readable data

--

`NA` or blank values introduced  

--

Problematic when grouping variables or observational units are broken


---

```{r, echo=FALSE, eval=TRUE}
olympics <- 
  tibble::tribble(
    ~Edition,    ~Country, ~`Soccer.gold.medal.(men)`, ~`Wrestling.(men.middleweight)`,
    NA,          NA,                         NA,           "weight class limit:",
    NA,          NA,                         NA,                         "82 kg",
    "Los Angeles 1984",       "USA",                   "France",                           "USA",
    "Barcelona",     "Spain",                    "Spain",                           "USA",
    "1992",          NA,                         NA,                              NA,
    "Atlanta 1996",       "USA",                  "Nigeria",                        "Russia",
    NA,          NA,                         NA,           "weight class limit:",
    NA,          NA,                         NA,                         "85 kg",
    "Sydney 2000", "Australia",                 "Cameroon",                        "Russia",
    "London",        "UK",                   "Mexico",                    "Azerbaijan",
    "2012",          NA,                         NA,                              NA
  )

```


.panelset[
.panel[.panel-name[olympics]
```{r olympicsgt, echo=FALSE, eval=TRUE}
gt(olympics) %>% 
  tab_options(table.font.size = 2)
```
]

.panel[.panel-name[Data setup]
```{r olympics_setup, fig.show='hide'}
olympics <- 
  tibble::tribble(
    ~Edition,    ~Country, ~`Soccer.gold.medal.(men)`, ~`Wrestling.(men.middleweight)`,
    NA,          NA,                         NA,           "weight class limit:",
    NA,          NA,                         NA,                         "82 kg",
    "Los Angeles 1984",       "USA",                   "France",                           "USA",
    "Barcelona",     "Spain",                    "Spain",                           "USA",
    "1992",          NA,                         NA,                              NA,
    "Atlanta 1996",       "USA",                  "Nigeria",                        "Russia",
    NA,          NA,                         NA,           "weight class limit:",
    NA,          NA,                         NA,                         "85 kg",
    "Sydney 2000", "Australia",                 "Cameroon",                        "Russia",
    "London",        "UK",                   "Mexico",                    "Azerbaijan",
    "2012",          NA,                         NA,                              NA
  )
```
]
]

---

## 'Unbreaking' values 

--

Values broken up across **two consecutive rows**

--

Match trailing or leading half of the value with a .orange.b[regexp] and ðŸ“¦ .rrured.b[`unheadr`]

---

## 'Unbreaking' values 

.pull-left[
Fast  
food  
Casual dining  
Thai  
Pizzeria  
Cakes and  
ice cream  
]  

.pull-right[
Retriever  
(flat-coated)  
Bulldog (American)   
Bullmastiff  
Retriever  
(golden)  
Poodle  
]

---

## 'Unbreaking' values

.pull-left[
Fast  
**food**  
Casual dining  
Thai  
Pizzeria  
Cakes and  
**ice cream**  
]  

.pull-right[
Retriever  
**(flat-coated)**  
Bulldog (American)   
Bullmastiff  
Retriever  
**(golden)**  
Poodle  
]

---

## **`unbreak_vals()`**  

.large[
verb-like function from ðŸ“¦ .rrured.b[`unheadr`]

Match the trailing half of the broken value with a .orange.b[regular expression]
]
```{r, eval=FALSE}
unbreak_vals(df, 
             regex, 
             ogcol, 
             newcol, 
             sep = " ",
)
```

---

## Trailing row


```{r, eval=TRUE}
olympics %>% 
  unbreak_vals(regex = "^\\d", # numbers at start of string
               ogcol = Edition,
               newcol = Edition_ub,
               sep = " ")
```

---

### **`unbreak_rows()`**  


Verb for merging rows from ðŸ“¦ .rrured.b[`unheadr`]

Match the leading half of the broken value with .orange.b[regular expression]


```{r, eval=FALSE}
unbreak_rows(df, 
             regex, 
             ogcol, 
             sep = " ")
```

---

## Leading row

```{r, eval=TRUE}
olympics %>% unbreak_rows(regex = "^weight", # numbers at start of string
                          ogcol = `Wrestling.(men.middleweight)`,
                          sep = " ")
```

---

## Leading and trailing rows

```{r, eval=TRUE}
olympics %>%
  unbreak_rows(
    regex = "^weight",
    ogcol = `Wrestling.(men.middleweight)`) %>%
  unbreak_vals(regex = "^\\d", # numbers at start of string
               ogcol = Edition,
               newcol = Edition_ub)
```

---

class: my-turn

## My turn

--

- Load the messy Age of Empires units dataset from csv (aoe_raw.csv)

--

- Identify the broken values in the 'Type' column and unbreak them


---
class: inverse
## Your turn

--

- Load the messy Age of Empires units dataset from csv (aoe_raw.csv)

--

- Identify the broken values in both the 'Type' and 'Name' columns and unbreak them

--

- Clean up any separator-related issues arising from the 'unbreaking'


---

class: center, middle, dk-section-title
background-image:url("images/david-hertle-8HAhmMk9HJI-unsplash.jpg")
background-size: cover

# Empty Rows and Columns

---

### Problems with empty rows and columns

--

- Common when importing files

--

- Problematic when referring to variables by position or ranges of consecutive variables  (`:`)  

--

- Potentially disruptive when filling adjacent cells

---

### What can we do?

--

**Identify** with ðŸ“¦ .rrured.b[`dplyr`]  

--

**Discard** with **`remove_empty()`** from ðŸ“¦ .rrured.b[`janitor`]

---

```{r, echo=FALSE, eval=TRUE}
universities <- 
  tibble::tribble(
    ~ID,                          ~Institution, ~year,    ~ZIP.code, ~Highest.degree.offered, ~County.name, ~Religious.affiliation,
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    100663L, "University of Alabama at Birmingham",    NA, "35294-0110",       "Doctor's degree",           NA,       "Not applicable",
    100690L,                  "Amridge University",    NA, "36117-3553",       "Doctor's degree",           NA,   "Churches of Christ",
    100706L, "University of Alabama in Huntsville",    NA,      "35899",       "Doctor's degree",           NA,       "Not applicable",
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    100751L,           "The University of Alabama",    NA, "35487-0166",       "Doctor's degree",           NA,       "Not applicable",
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    101541L,                      "Judson College",    NA,      "36756",     "Bachelor's degree",           NA,              "Baptist",
    101587L,          "University of West Alabama",    NA,      "35470",       "Master's degree",           NA,       "Not applicable",
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    101693L,                "University of Mobile",    NA, "36613-2842",       "Master's degree",           NA,     "Southern Baptist"
  )

```

.panelset[
.panel[.panel-name[universities]
```{r, echo=FALSE, eval=TRUE}
universities%>% gt() %>% 
  tab_options(table.background.color="#f4f4f9", table.font.size = pct(8))
```
]

.panel[.panel-name[Data setup]
```{r unissetup, fig.show='hide'}
universities <- 
  tibble::tribble(
    ~ID,                          ~Institution, ~year,    ~ZIP.code, ~Highest.degree.offered, ~County.name, ~Religious.affiliation,
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    100663L, "University of Alabama at Birmingham",    NA, "35294-0110",       "Doctor's degree",           NA,       "Not applicable",
    100690L,                  "Amridge University",    NA, "36117-3553",       "Doctor's degree",           NA,   "Churches of Christ",
    100706L, "University of Alabama in Huntsville",    NA,      "35899",       "Doctor's degree",           NA,       "Not applicable",
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    100751L,           "The University of Alabama",    NA, "35487-0166",       "Doctor's degree",           NA,       "Not applicable",
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    101541L,                      "Judson College",    NA,      "36756",     "Bachelor's degree",           NA,              "Baptist",
    101587L,          "University of West Alabama",    NA,      "35470",       "Master's degree",           NA,       "Not applicable",
    NA,                                    NA,    NA,           NA,                      NA,           NA,                     NA,
    101693L,                "University of Mobile",    NA, "36613-2842",       "Master's degree",           NA,     "Southern Baptist"
  )
```
]
]
.small[source: US Integrated Postsecondary Education Data System (IPEDS)]

---


## Identify empty rows with ðŸ“¦ .rrured.b[`dplyr`] (and ðŸ“¦ .rrured.b[`tibble`])  

```{r, eval=TRUE}
universities %>% filter(across(everything(), is.na))
universities %>% filter(across(everything(), is.na)) %>% nrow()
```

---

### Add unique identifier first

```{r, eval=TRUE}
universities %>% 
  rowid_to_column() %>% #<<
  filter(across(-rowid, is.na)) 
```

---

### Negate the condition and discard empty rows

```{r, eval=TRUE}
universities %>% 
  filter(!across(everything(), is.na))
```

---

### Discard empty rows with with **`remove_empty()`** from ðŸ“¦ .rrured.b[`janitor`]  

> `quiet = FALSE` prints a statement about the rows that were removed

```{r message=TRUE, eval=TRUE}
universities %>% 
  remove_empty(which = "rows",
               quiet = FALSE) 
```

---

## Empty columns 

.large[
Identify with ðŸ“¦ .rrured.b[`dplyr`] and **`all_na()`** from ðŸ“¦ .rrured.b[`naniar`]  
]

```{r, eval=TRUE}
universities %>% 
  select(where(all_na))
```

---

### Identify and get names

```{r, eval=TRUE}
universities %>% 
  select(where(all_na)) %>% 
  names()
```

---

### Negate condition for selection, get names


```{r, eval=TRUE}
universities %>% 
  select(!where(all_na)) %>% 
  names()
```

---

### Discard empty columns with with **`remove_empty()`** from ðŸ“¦ .rrured.b[`janitor`]  


```{r, eval=TRUE, message=TRUE}
universities %>% 
  remove_empty(which= "cols", quiet = FALSE) 
```


---

class: my-turn

## My turn

--

- Import the Marine Protected Areas dataset (MPAS-mine.csv)

--

- Identify the empty rows and columns, and create a new object with only the empty rows and columns 

--

- Remove the empty rows and columns 


---
class: inverse

## Your turn

--

- Import the Marine Protected Areas dataset (MPAS-your.csv)

--

- Identify the empty rows and columns, and create a new object with only the empty rows and columns 

--

- Remove the empty rows and columns

--

---

class: center, middle, dk-section-title
background-image:url("images/markus-spiske-4jiR57y3jgY-unsplash.jpg")
background-size: cover
# Parsing Numbers

---
class: middle

.large[
- Vectors must have all their values of the same mode (_character, numeric, logical_)]

--

.large[
- If there is a character string is present in a vector, everything else in the vector will be converted to character strings
]

---

### We cannot perform arithmetic operations on:

--

- **Numbers stored as text**

--

- **Strings with non-digits**

--

```{r message=TRUE, warning=TRUE, eval=TRUE}
test_scores <- c(8.8,9,10,7.2,8.4)
class(test_scores)
class(c(test_scores,"a"))
```

---

## Numbers stored as text


1. **`type_convert()`** the whole object (ðŸ“¦ .rrured.b[`readr`])

--

2. Coerce one or more variables to `numeric` with ðŸ“¦ .rrured.b[`dplyr`]


---

## Strings with non-digits


1. Parse with ðŸ“¦ .rrured.b[`readr`]  

2. Clean with .orange.b[regular expressions]


---
```{r, include=FALSE, eval=TRUE}
burger_prices <- 
  tibble::tribble(
    ~Rank,        ~Country,   ~Price, ~Price.ARS,   ~Region,
    "1",   "Switzerland",    "6.8",  "$544.50",  "Europe",
    "2",        "Norway",    "6.2",      "496",  "Europe",
    "3",        "Sweden",    "6.1",      "488",  "Europe",
    "4",       "Finland",    "5.6",      "448",  "Europe",
    "5", "United States", "5.3[1]",  "$424.50", "America",
    "8",         "Italy",    "5.1",      "408",  "Europe",
    "7",        "France",    "5.1",   "408,50",  "Europe",
    "6",        "Canada",    "5.3",      "424", "America",
    "9",        "Brazil",   "5.1*",      "408", "America"
  )

```

.panelset[
.panel[.panel-name[Burger Prices]
```{r, echo=FALSE, eval=TRUE}
burger_prices %>% gt() %>% tab_options(table.background.color="#f4f4f9",container.overflow.x = TRUE, container.overflow.y = TRUE)
```
]

.panel[.panel-name[Data setup]
```{r burgerssetup, fig.show='hide'}
burger_prices <- 
  tibble::tribble(
    ~Rank,        ~Country,   ~Price, ~Price.ARS,   ~Region,
    "1",   "Switzerland",    "6.8",  "$544.50",  "Europe",
    "2",        "Norway",    "6.2",      "496",  "Europe",
    "3",        "Sweden",    "6.1",      "488",  "Europe",
    "4",       "Finland",    "5.6",      "448",  "Europe",
    "5", "United States", "5.3[1]",  "$424.50", "America",
    "8",         "Italy",    "5.1",      "408",  "Europe",
    "7",        "France",    "5.1",   "408,50",  "Europe",
    "6",        "Canada",    "5.3",      "424", "America",
    "9",        "Brazil",   "5.1*",      "408", "America"
  )
```
]
]

---

## Numbers stored as text  

Parse all columns

```{r, eval=TRUE}
burger_prices %>% 
  type_convert()
```

---

## Numbers stored as text  

Coerce variables to `numeric`

```{r, eval=TRUE}
burger_prices %>% 
  mutate(Rank = as.numeric(Rank))
```

> âš  be careful of problems when coercing strings with non-digits

---

## Strings with non-digits

Parse with ðŸ“¦ .rrured.b[`readr`]

> âš  be careful of problems when parsing strings with non-digits

```{r, eval=TRUE}
burger_prices %>% 
  mutate(across(c(Rank, Price, Price.ARS), parse_number))
```



---

## Strings with non-digits

Clean with .orange.b[regular expressions] and `type_convert()`


```{r, echo=FALSE, eval=TRUE}
options(pillar.sigfig=5)
```


```{r, eval=TRUE}
burger_prices %>%
  mutate(across(c(Rank, Price, Price.ARS), str_remove_all, "\\[.+\\]|\\(.+\\)")) %>%
  mutate(across(c(Rank, Price, Price.ARS), str_remove_all, "[^0-9.,]")) %>%
  mutate(Price.ARS = str_replace(Price.ARS, ",", ".")) %>% 
  type_convert()
```

---
class: my-turn
## My turn

--

- Import the Marine Protected Areas dataset (MPAS-mine.csv)

--

- Make the columns that hold the MPA extent into usable numeric variables


---
class: inverse
## Your turn

--

- Import the Marine Protected Areas dataset (MPAS-mine.csv)

--

- Subset to keep only the MPA names and columns with extent data

--

- Make the columns that hold the MPA extent into usable numeric variables

--

- Watch out for the decimals


---

class: center, middle, dk-section-title
background-image:url("images/ryan-quintal-US9Tc9pKNBU-unsplash.jpg")
background-size: cover


# Putting Everything Together

---

## Demonstration

.large[Watch me load and wrangle the messy Age of Empires units dataset into a usable, tidy object]